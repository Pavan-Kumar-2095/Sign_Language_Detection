{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec34832-69cb-424e-a302-e14be346b308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X[0]: (63,)\n",
      "Number of elements in X[0]: 63\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=1)  # Detect only one hand\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Set the path to your dataset\n",
    "path_to_data = \"./new_alpha_2/\" \n",
    "\n",
    "# Initialize a dictionary to hold file paths for each class\n",
    "Sign_file_names_dict = {}\n",
    "\n",
    "# Populate the dictionary with image file paths\n",
    "for img_dir in os.scandir(path_to_data):\n",
    "    if img_dir.is_dir():\n",
    "        sign_name = img_dir.name\n",
    "        Sign_file_names_dict[sign_name] = []\n",
    "        for entry in os.scandir(img_dir.path):\n",
    "            if entry.is_file() and entry.name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                Sign_file_names_dict[sign_name].append(entry.path)\n",
    "\n",
    "# Define the class labels\n",
    "class_dict = {name: idx for idx, name in enumerate(Sign_file_names_dict.keys())}\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(Sign_file_names_dict, class_dict, image_size=(100, 100)):\n",
    "    X, y = [], []\n",
    "    for sign_name, image_paths in Sign_file_names_dict.items():\n",
    "        for image_path in image_paths:\n",
    "            # Load the image\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                print(f\"Error loading image: {image_path}\")\n",
    "                continue\n",
    "            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(imgRGB)\n",
    "\n",
    "            landmarks = []\n",
    "            if results.multi_hand_landmarks:\n",
    "                # Process the first detected hand\n",
    "                handLms = results.multi_hand_landmarks[0]\n",
    "                for lm in handLms.landmark:\n",
    "                    landmarks.extend([lm.x, lm.y, lm.z])\n",
    "            else:\n",
    "                # If no hand is detected, append zeros\n",
    "                landmarks = [0.0] * 63  # 21 landmarks * 3 coordinates\n",
    "\n",
    "            # Resize the image\n",
    "            img_resized = cv2.resize(img, image_size)\n",
    "            # Normalize the image\n",
    "            img_normalized = img_resized / 255.0\n",
    "\n",
    "            X.append(landmarks)\n",
    "            y.append(class_dict[sign_name])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Load and preprocess the data\n",
    "X, y = load_and_preprocess_images(Sign_file_names_dict, class_dict)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the shape of the first sample\n",
    "print(f\"Shape of X[0]: {X[0].shape}\")\n",
    "print(f\"Number of elements in X[0]: {len(X[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6739e3-5974-4f0b-8b2d-5d2e755750f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float_and_round(input_list):\n",
    "    return list(map(lambda x: round(float(x), 4), input_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa90bebc-e7f2-4142-9d22-82e226236277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'del': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 'space': 20,\n",
       " 't': 21,\n",
       " 'u': 22,\n",
       " 'v': 23,\n",
       " 'w': 24,\n",
       " 'x': 25,\n",
       " 'y': 26,\n",
       " 'z': 27}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X))\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2737597b-3f5e-4e66-9d4a-ca9766a60358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavan-kumar\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.0438 - loss: 3.3145 - val_accuracy: 0.1002 - val_loss: 3.2416\n",
      "Epoch 2/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1444 - loss: 3.1866 - val_accuracy: 0.1932 - val_loss: 3.0656\n",
      "Epoch 3/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2771 - loss: 2.9567 - val_accuracy: 0.3005 - val_loss: 2.7576\n",
      "Epoch 4/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3516 - loss: 2.6213 - val_accuracy: 0.4043 - val_loss: 2.4005\n",
      "Epoch 5/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4315 - loss: 2.2753 - val_accuracy: 0.4633 - val_loss: 2.0808\n",
      "Epoch 6/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4897 - loss: 1.9816 - val_accuracy: 0.5081 - val_loss: 1.8639\n",
      "Epoch 7/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5287 - loss: 1.7763 - val_accuracy: 0.5725 - val_loss: 1.6476\n",
      "Epoch 8/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6028 - loss: 1.5638 - val_accuracy: 0.6565 - val_loss: 1.4756\n",
      "Epoch 9/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6575 - loss: 1.3756 - val_accuracy: 0.6798 - val_loss: 1.3402\n",
      "Epoch 10/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6645 - loss: 1.2914 - val_accuracy: 0.6744 - val_loss: 1.2228\n",
      "Epoch 11/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6814 - loss: 1.1933 - val_accuracy: 0.6816 - val_loss: 1.1400\n",
      "Epoch 12/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7186 - loss: 1.0834 - val_accuracy: 0.6923 - val_loss: 1.0701\n",
      "Epoch 13/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7276 - loss: 1.0211 - val_accuracy: 0.7066 - val_loss: 0.9866\n",
      "Epoch 14/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7386 - loss: 0.9293 - val_accuracy: 0.7299 - val_loss: 0.9252\n",
      "Epoch 15/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7554 - loss: 0.8950 - val_accuracy: 0.7728 - val_loss: 0.8680\n",
      "Epoch 16/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7781 - loss: 0.8663 - val_accuracy: 0.7746 - val_loss: 0.8311\n",
      "Epoch 17/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7803 - loss: 0.8206 - val_accuracy: 0.7996 - val_loss: 0.7858\n",
      "Epoch 18/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8020 - loss: 0.7665 - val_accuracy: 0.8050 - val_loss: 0.7507\n",
      "Epoch 19/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8047 - loss: 0.7424 - val_accuracy: 0.8283 - val_loss: 0.7241\n",
      "Epoch 20/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8255 - loss: 0.7205 - val_accuracy: 0.8283 - val_loss: 0.6934\n",
      "Epoch 21/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8198 - loss: 0.6886 - val_accuracy: 0.8211 - val_loss: 0.6798\n",
      "Epoch 22/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8173 - loss: 0.6810 - val_accuracy: 0.8122 - val_loss: 0.6620\n",
      "Epoch 23/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8328 - loss: 0.6231 - val_accuracy: 0.8479 - val_loss: 0.6204\n",
      "Epoch 24/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8285 - loss: 0.6449 - val_accuracy: 0.8462 - val_loss: 0.6086\n",
      "Epoch 25/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8563 - loss: 0.5645 - val_accuracy: 0.8479 - val_loss: 0.5925\n",
      "Epoch 26/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8461 - loss: 0.5591 - val_accuracy: 0.8551 - val_loss: 0.5703\n",
      "Epoch 27/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8515 - loss: 0.5669 - val_accuracy: 0.8587 - val_loss: 0.5578\n",
      "Epoch 28/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8419 - loss: 0.5726 - val_accuracy: 0.8658 - val_loss: 0.5427\n",
      "Epoch 29/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8637 - loss: 0.5260 - val_accuracy: 0.8533 - val_loss: 0.5286\n",
      "Epoch 30/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8561 - loss: 0.5326 - val_accuracy: 0.8640 - val_loss: 0.5140\n",
      "Epoch 31/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8566 - loss: 0.5299 - val_accuracy: 0.8623 - val_loss: 0.5058\n",
      "Epoch 32/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8658 - loss: 0.4931 - val_accuracy: 0.8676 - val_loss: 0.5086\n",
      "Epoch 33/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8580 - loss: 0.5046 - val_accuracy: 0.8712 - val_loss: 0.4871\n",
      "Epoch 34/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8796 - loss: 0.4609 - val_accuracy: 0.8640 - val_loss: 0.4838\n",
      "Epoch 35/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8508 - loss: 0.5204 - val_accuracy: 0.8766 - val_loss: 0.4691\n",
      "Epoch 36/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8729 - loss: 0.4851 - val_accuracy: 0.8766 - val_loss: 0.4589\n",
      "Epoch 37/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8710 - loss: 0.4932 - val_accuracy: 0.8658 - val_loss: 0.4807\n",
      "Epoch 38/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8686 - loss: 0.4964 - val_accuracy: 0.8676 - val_loss: 0.4755\n",
      "Epoch 39/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8784 - loss: 0.4403 - val_accuracy: 0.8819 - val_loss: 0.4347\n",
      "Epoch 40/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8829 - loss: 0.4394 - val_accuracy: 0.8784 - val_loss: 0.4324\n",
      "Epoch 41/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8759 - loss: 0.4516 - val_accuracy: 0.8676 - val_loss: 0.4523\n",
      "Epoch 42/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8591 - loss: 0.4518 - val_accuracy: 0.8784 - val_loss: 0.4213\n",
      "Epoch 43/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8850 - loss: 0.4290 - val_accuracy: 0.8819 - val_loss: 0.4123\n",
      "Epoch 44/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8853 - loss: 0.4043 - val_accuracy: 0.8801 - val_loss: 0.4271\n",
      "Epoch 45/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8875 - loss: 0.4161 - val_accuracy: 0.8873 - val_loss: 0.4087\n",
      "Epoch 46/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8930 - loss: 0.4155 - val_accuracy: 0.8855 - val_loss: 0.4106\n",
      "Epoch 47/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8784 - loss: 0.4222 - val_accuracy: 0.8855 - val_loss: 0.4059\n",
      "Epoch 48/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8730 - loss: 0.4191 - val_accuracy: 0.8873 - val_loss: 0.4046\n",
      "Epoch 49/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8935 - loss: 0.4051 - val_accuracy: 0.8676 - val_loss: 0.4026\n",
      "Epoch 50/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8856 - loss: 0.3932 - val_accuracy: 0.8909 - val_loss: 0.3933\n",
      "Epoch 51/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8950 - loss: 0.3885 - val_accuracy: 0.8855 - val_loss: 0.3858\n",
      "Epoch 52/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8911 - loss: 0.3755 - val_accuracy: 0.8837 - val_loss: 0.3914\n",
      "Epoch 53/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8887 - loss: 0.3957 - val_accuracy: 0.8873 - val_loss: 0.3858\n",
      "Epoch 54/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8748 - loss: 0.4159 - val_accuracy: 0.8927 - val_loss: 0.3764\n",
      "Epoch 55/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8981 - loss: 0.3663 - val_accuracy: 0.8909 - val_loss: 0.3807\n",
      "Epoch 56/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8958 - loss: 0.3752 - val_accuracy: 0.8855 - val_loss: 0.3732\n",
      "Epoch 57/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8927 - loss: 0.3824 - val_accuracy: 0.8891 - val_loss: 0.3759\n",
      "Epoch 58/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8921 - loss: 0.3753 - val_accuracy: 0.8891 - val_loss: 0.3628\n",
      "Epoch 59/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8887 - loss: 0.3646 - val_accuracy: 0.8945 - val_loss: 0.3639\n",
      "Epoch 60/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8815 - loss: 0.4270 - val_accuracy: 0.8962 - val_loss: 0.3589\n",
      "Epoch 61/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8830 - loss: 0.3865 - val_accuracy: 0.8998 - val_loss: 0.3548\n",
      "Epoch 62/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9069 - loss: 0.3507 - val_accuracy: 0.8962 - val_loss: 0.3557\n",
      "Epoch 63/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9001 - loss: 0.3688 - val_accuracy: 0.8980 - val_loss: 0.3525\n",
      "Epoch 64/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8914 - loss: 0.3565 - val_accuracy: 0.8927 - val_loss: 0.3556\n",
      "Epoch 65/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8898 - loss: 0.3611 - val_accuracy: 0.8980 - val_loss: 0.3514\n",
      "Epoch 66/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9028 - loss: 0.3514 - val_accuracy: 0.8998 - val_loss: 0.3526\n",
      "Epoch 67/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8959 - loss: 0.3576 - val_accuracy: 0.8891 - val_loss: 0.3491\n",
      "Epoch 68/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8947 - loss: 0.3631 - val_accuracy: 0.9034 - val_loss: 0.3453\n",
      "Epoch 69/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8988 - loss: 0.3547 - val_accuracy: 0.8945 - val_loss: 0.3455\n",
      "Epoch 70/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8940 - loss: 0.3517 - val_accuracy: 0.8998 - val_loss: 0.3392\n",
      "Epoch 71/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9040 - loss: 0.3434 - val_accuracy: 0.8962 - val_loss: 0.3433\n",
      "Epoch 72/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9016 - loss: 0.3296 - val_accuracy: 0.8980 - val_loss: 0.3490\n",
      "Epoch 73/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8972 - loss: 0.3411 - val_accuracy: 0.8980 - val_loss: 0.3504\n",
      "Epoch 74/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9064 - loss: 0.3391 - val_accuracy: 0.8980 - val_loss: 0.3473\n",
      "Epoch 75/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9013 - loss: 0.3304 - val_accuracy: 0.9016 - val_loss: 0.3354\n",
      "Epoch 76/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8975 - loss: 0.3479 - val_accuracy: 0.8945 - val_loss: 0.3330\n",
      "Epoch 77/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8996 - loss: 0.3537 - val_accuracy: 0.8962 - val_loss: 0.3342\n",
      "Epoch 78/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8967 - loss: 0.3497 - val_accuracy: 0.8998 - val_loss: 0.3338\n",
      "Epoch 79/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8975 - loss: 0.3432 - val_accuracy: 0.8962 - val_loss: 0.3358\n",
      "Epoch 80/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9108 - loss: 0.3084 - val_accuracy: 0.8980 - val_loss: 0.3260\n",
      "Epoch 81/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9037 - loss: 0.3323 - val_accuracy: 0.9016 - val_loss: 0.3326\n",
      "Epoch 82/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9106 - loss: 0.3140 - val_accuracy: 0.9052 - val_loss: 0.3209\n",
      "Epoch 83/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8967 - loss: 0.3252 - val_accuracy: 0.8927 - val_loss: 0.3485\n",
      "Epoch 84/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9163 - loss: 0.2883 - val_accuracy: 0.8998 - val_loss: 0.3324\n",
      "Epoch 85/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9106 - loss: 0.3025 - val_accuracy: 0.8962 - val_loss: 0.3410\n",
      "Epoch 86/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8994 - loss: 0.3341 - val_accuracy: 0.8962 - val_loss: 0.3366\n",
      "Epoch 87/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9156 - loss: 0.2891 - val_accuracy: 0.8927 - val_loss: 0.3358\n",
      "Epoch 88/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8814 - loss: 0.3671 - val_accuracy: 0.8945 - val_loss: 0.3267\n",
      "Epoch 89/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8943 - loss: 0.3447 - val_accuracy: 0.9052 - val_loss: 0.3253\n",
      "Epoch 90/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9086 - loss: 0.3102 - val_accuracy: 0.9016 - val_loss: 0.3171\n",
      "Epoch 91/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9158 - loss: 0.2757 - val_accuracy: 0.9052 - val_loss: 0.3228\n",
      "Epoch 92/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9143 - loss: 0.2894 - val_accuracy: 0.8945 - val_loss: 0.3345\n",
      "Epoch 93/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8957 - loss: 0.3413 - val_accuracy: 0.8998 - val_loss: 0.3223\n",
      "Epoch 94/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9051 - loss: 0.3261 - val_accuracy: 0.9016 - val_loss: 0.3175\n",
      "Epoch 95/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9156 - loss: 0.2776 - val_accuracy: 0.9070 - val_loss: 0.3174\n",
      "Epoch 96/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8936 - loss: 0.3442 - val_accuracy: 0.8998 - val_loss: 0.3351\n",
      "Epoch 97/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9073 - loss: 0.3086 - val_accuracy: 0.8998 - val_loss: 0.3254\n",
      "Epoch 98/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9072 - loss: 0.3151 - val_accuracy: 0.9052 - val_loss: 0.3137\n",
      "Epoch 99/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9045 - loss: 0.3143 - val_accuracy: 0.8998 - val_loss: 0.3205\n",
      "Epoch 100/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9021 - loss: 0.3256 - val_accuracy: 0.9052 - val_loss: 0.3125\n",
      "Epoch 101/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9165 - loss: 0.2873 - val_accuracy: 0.9052 - val_loss: 0.3108\n",
      "Epoch 102/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9141 - loss: 0.2801 - val_accuracy: 0.9034 - val_loss: 0.3112\n",
      "Epoch 103/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9061 - loss: 0.3028 - val_accuracy: 0.9034 - val_loss: 0.3140\n",
      "Epoch 104/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9073 - loss: 0.3058 - val_accuracy: 0.9034 - val_loss: 0.3120\n",
      "Epoch 105/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9131 - loss: 0.2890 - val_accuracy: 0.9070 - val_loss: 0.3090\n",
      "Epoch 106/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9030 - loss: 0.3231 - val_accuracy: 0.8909 - val_loss: 0.3343\n",
      "Epoch 107/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8948 - loss: 0.3217 - val_accuracy: 0.9052 - val_loss: 0.3087\n",
      "Epoch 108/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9054 - loss: 0.3029 - val_accuracy: 0.9052 - val_loss: 0.3244\n",
      "Epoch 109/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9037 - loss: 0.3115 - val_accuracy: 0.9070 - val_loss: 0.3019\n",
      "Epoch 110/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9109 - loss: 0.2860 - val_accuracy: 0.9016 - val_loss: 0.3099\n",
      "Epoch 111/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9066 - loss: 0.3056 - val_accuracy: 0.8927 - val_loss: 0.3262\n",
      "Epoch 112/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9131 - loss: 0.2837 - val_accuracy: 0.8998 - val_loss: 0.3154\n",
      "Epoch 113/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9059 - loss: 0.3039 - val_accuracy: 0.9034 - val_loss: 0.3124\n",
      "Epoch 114/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9045 - loss: 0.3086 - val_accuracy: 0.9106 - val_loss: 0.3044\n",
      "Epoch 115/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9174 - loss: 0.2901 - val_accuracy: 0.9016 - val_loss: 0.3163\n",
      "Epoch 116/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9178 - loss: 0.2690 - val_accuracy: 0.9052 - val_loss: 0.3063\n",
      "Epoch 117/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9193 - loss: 0.2748 - val_accuracy: 0.9034 - val_loss: 0.3048\n",
      "Epoch 118/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9114 - loss: 0.2895 - val_accuracy: 0.9070 - val_loss: 0.3050\n",
      "Epoch 119/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9030 - loss: 0.3151 - val_accuracy: 0.9070 - val_loss: 0.2965\n",
      "Epoch 120/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9091 - loss: 0.2828 - val_accuracy: 0.9052 - val_loss: 0.3048\n",
      "Epoch 121/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9210 - loss: 0.2570 - val_accuracy: 0.9052 - val_loss: 0.3096\n",
      "Epoch 122/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9157 - loss: 0.2751 - val_accuracy: 0.9070 - val_loss: 0.3002\n",
      "Epoch 123/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9221 - loss: 0.2660 - val_accuracy: 0.9016 - val_loss: 0.3104\n",
      "Epoch 124/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9161 - loss: 0.2742 - val_accuracy: 0.9070 - val_loss: 0.3010\n",
      "Epoch 125/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9105 - loss: 0.2825 - val_accuracy: 0.9034 - val_loss: 0.3083\n",
      "Epoch 126/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8966 - loss: 0.3257 - val_accuracy: 0.9052 - val_loss: 0.3090\n",
      "Epoch 127/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9166 - loss: 0.2719 - val_accuracy: 0.9052 - val_loss: 0.3070\n",
      "Epoch 128/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9094 - loss: 0.3012 - val_accuracy: 0.9106 - val_loss: 0.3035\n",
      "Epoch 129/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9199 - loss: 0.2652 - val_accuracy: 0.9070 - val_loss: 0.3005\n",
      "Epoch 130/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9184 - loss: 0.2702 - val_accuracy: 0.9052 - val_loss: 0.2992\n",
      "Epoch 131/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9186 - loss: 0.2608 - val_accuracy: 0.9070 - val_loss: 0.2974\n",
      "Epoch 132/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8951 - loss: 0.3214 - val_accuracy: 0.9034 - val_loss: 0.3163\n",
      "Epoch 133/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9058 - loss: 0.3010 - val_accuracy: 0.9034 - val_loss: 0.3028\n",
      "Epoch 134/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9195 - loss: 0.2690 - val_accuracy: 0.9034 - val_loss: 0.3106\n",
      "Epoch 135/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9147 - loss: 0.2776 - val_accuracy: 0.9106 - val_loss: 0.3025\n",
      "Epoch 136/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9130 - loss: 0.2794 - val_accuracy: 0.9052 - val_loss: 0.2941\n",
      "Epoch 137/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9136 - loss: 0.2828 - val_accuracy: 0.8998 - val_loss: 0.3144\n",
      "Epoch 138/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9173 - loss: 0.2630 - val_accuracy: 0.9070 - val_loss: 0.2991\n",
      "Epoch 139/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9139 - loss: 0.2744 - val_accuracy: 0.9052 - val_loss: 0.3048\n",
      "Epoch 140/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9182 - loss: 0.2773 - val_accuracy: 0.9016 - val_loss: 0.3101\n",
      "Epoch 141/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9080 - loss: 0.2801 - val_accuracy: 0.9016 - val_loss: 0.3171\n",
      "Epoch 142/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9035 - loss: 0.3004 - val_accuracy: 0.9070 - val_loss: 0.3086\n",
      "Epoch 143/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9170 - loss: 0.2630 - val_accuracy: 0.9052 - val_loss: 0.2976\n",
      "Epoch 144/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9169 - loss: 0.2729 - val_accuracy: 0.9070 - val_loss: 0.2965\n",
      "Epoch 145/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9090 - loss: 0.2693 - val_accuracy: 0.9070 - val_loss: 0.3022\n",
      "Epoch 146/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9020 - loss: 0.3146 - val_accuracy: 0.9052 - val_loss: 0.3013\n",
      "Epoch 147/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9111 - loss: 0.2888 - val_accuracy: 0.9123 - val_loss: 0.2916\n",
      "Epoch 148/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9141 - loss: 0.2739 - val_accuracy: 0.9016 - val_loss: 0.3095\n",
      "Epoch 149/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9194 - loss: 0.2682 - val_accuracy: 0.9070 - val_loss: 0.2952\n",
      "Epoch 150/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9114 - loss: 0.2823 - val_accuracy: 0.9106 - val_loss: 0.2963\n",
      "Epoch 151/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9092 - loss: 0.2807 - val_accuracy: 0.9088 - val_loss: 0.3006\n",
      "Epoch 152/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9211 - loss: 0.2695 - val_accuracy: 0.9070 - val_loss: 0.2934\n",
      "Epoch 153/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9229 - loss: 0.2616 - val_accuracy: 0.9016 - val_loss: 0.3026\n",
      "Epoch 154/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9182 - loss: 0.2762 - val_accuracy: 0.9016 - val_loss: 0.3071\n",
      "Epoch 155/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9118 - loss: 0.2933 - val_accuracy: 0.9088 - val_loss: 0.2949\n",
      "Epoch 156/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9046 - loss: 0.3006 - val_accuracy: 0.9052 - val_loss: 0.3035\n",
      "Epoch 157/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9110 - loss: 0.2811 - val_accuracy: 0.9070 - val_loss: 0.2952\n",
      "Epoch 158/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9086 - loss: 0.2818 - val_accuracy: 0.9088 - val_loss: 0.2945\n",
      "Epoch 159/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9111 - loss: 0.2663 - val_accuracy: 0.9016 - val_loss: 0.3017\n",
      "Epoch 160/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9102 - loss: 0.2843 - val_accuracy: 0.9088 - val_loss: 0.2893\n",
      "Epoch 161/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9172 - loss: 0.2763 - val_accuracy: 0.8998 - val_loss: 0.3015\n",
      "Epoch 162/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9112 - loss: 0.2951 - val_accuracy: 0.9016 - val_loss: 0.3094\n",
      "Epoch 163/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9136 - loss: 0.2836 - val_accuracy: 0.9106 - val_loss: 0.2964\n",
      "Epoch 164/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9093 - loss: 0.2853 - val_accuracy: 0.9088 - val_loss: 0.2913\n",
      "Epoch 165/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9218 - loss: 0.2651 - val_accuracy: 0.9052 - val_loss: 0.2956\n",
      "Epoch 166/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9164 - loss: 0.2611 - val_accuracy: 0.9070 - val_loss: 0.2877\n",
      "Epoch 167/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9109 - loss: 0.2973 - val_accuracy: 0.9106 - val_loss: 0.2885\n",
      "Epoch 168/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9111 - loss: 0.2848 - val_accuracy: 0.9088 - val_loss: 0.2919\n",
      "Epoch 169/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9137 - loss: 0.2663 - val_accuracy: 0.9052 - val_loss: 0.3046\n",
      "Epoch 170/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9148 - loss: 0.2753 - val_accuracy: 0.9106 - val_loss: 0.2872\n",
      "Epoch 171/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9210 - loss: 0.2512 - val_accuracy: 0.9141 - val_loss: 0.2844\n",
      "Epoch 172/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9135 - loss: 0.2817 - val_accuracy: 0.9123 - val_loss: 0.2922\n",
      "Epoch 173/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9073 - loss: 0.2829 - val_accuracy: 0.9016 - val_loss: 0.3013\n",
      "Epoch 174/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9118 - loss: 0.2668 - val_accuracy: 0.9106 - val_loss: 0.2952\n",
      "Epoch 175/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9118 - loss: 0.2758 - val_accuracy: 0.9052 - val_loss: 0.3031\n",
      "Epoch 176/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9150 - loss: 0.2721 - val_accuracy: 0.9034 - val_loss: 0.3157\n",
      "Epoch 177/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9169 - loss: 0.2781 - val_accuracy: 0.9070 - val_loss: 0.2999\n",
      "Epoch 178/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9123 - loss: 0.2660 - val_accuracy: 0.9016 - val_loss: 0.3095\n",
      "Epoch 179/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9147 - loss: 0.2602 - val_accuracy: 0.9088 - val_loss: 0.2890\n",
      "Epoch 180/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9147 - loss: 0.2879 - val_accuracy: 0.9088 - val_loss: 0.2899\n",
      "Epoch 181/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9227 - loss: 0.2592 - val_accuracy: 0.9070 - val_loss: 0.3041\n",
      "Epoch 182/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9300 - loss: 0.2347 - val_accuracy: 0.9052 - val_loss: 0.2949\n",
      "Epoch 183/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9123 - loss: 0.2667 - val_accuracy: 0.9106 - val_loss: 0.2889\n",
      "Epoch 184/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9241 - loss: 0.2606 - val_accuracy: 0.9034 - val_loss: 0.2966\n",
      "Epoch 185/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9163 - loss: 0.2676 - val_accuracy: 0.9070 - val_loss: 0.2911\n",
      "Epoch 186/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9199 - loss: 0.2596 - val_accuracy: 0.9088 - val_loss: 0.2873\n",
      "Epoch 187/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9221 - loss: 0.2485 - val_accuracy: 0.9052 - val_loss: 0.3118\n",
      "Epoch 188/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9094 - loss: 0.2700 - val_accuracy: 0.9141 - val_loss: 0.2838\n",
      "Epoch 189/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9135 - loss: 0.2850 - val_accuracy: 0.9106 - val_loss: 0.2903\n",
      "Epoch 190/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9259 - loss: 0.2429 - val_accuracy: 0.9052 - val_loss: 0.2978\n",
      "Epoch 191/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9181 - loss: 0.2772 - val_accuracy: 0.9034 - val_loss: 0.2923\n",
      "Epoch 192/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9268 - loss: 0.2315 - val_accuracy: 0.9052 - val_loss: 0.2959\n",
      "Epoch 193/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9245 - loss: 0.2423 - val_accuracy: 0.9052 - val_loss: 0.2944\n",
      "Epoch 194/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9022 - loss: 0.3107 - val_accuracy: 0.9088 - val_loss: 0.2863\n",
      "Epoch 195/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9227 - loss: 0.2386 - val_accuracy: 0.9052 - val_loss: 0.2935\n",
      "Epoch 196/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9154 - loss: 0.2639 - val_accuracy: 0.9070 - val_loss: 0.2937\n",
      "Epoch 197/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9124 - loss: 0.2763 - val_accuracy: 0.9141 - val_loss: 0.2824\n",
      "Epoch 198/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9185 - loss: 0.2473 - val_accuracy: 0.9106 - val_loss: 0.2907\n",
      "Epoch 199/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9284 - loss: 0.2352 - val_accuracy: 0.9106 - val_loss: 0.2950\n",
      "Epoch 200/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9150 - loss: 0.2901 - val_accuracy: 0.9141 - val_loss: 0.2921\n",
      "Epoch 201/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9164 - loss: 0.2715 - val_accuracy: 0.9070 - val_loss: 0.2948\n",
      "Epoch 202/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9199 - loss: 0.2520 - val_accuracy: 0.9034 - val_loss: 0.2940\n",
      "Epoch 203/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9149 - loss: 0.2745 - val_accuracy: 0.8945 - val_loss: 0.3329\n",
      "Epoch 204/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9057 - loss: 0.2967 - val_accuracy: 0.9052 - val_loss: 0.3020\n",
      "Epoch 205/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9208 - loss: 0.2582 - val_accuracy: 0.9123 - val_loss: 0.2821\n",
      "Epoch 206/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9207 - loss: 0.2591 - val_accuracy: 0.9106 - val_loss: 0.2931\n",
      "Epoch 207/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9288 - loss: 0.2307 - val_accuracy: 0.9106 - val_loss: 0.2844\n",
      "Epoch 208/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9204 - loss: 0.2393 - val_accuracy: 0.9123 - val_loss: 0.2887\n",
      "Epoch 209/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9169 - loss: 0.2623 - val_accuracy: 0.9088 - val_loss: 0.2946\n",
      "Epoch 210/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9196 - loss: 0.2543 - val_accuracy: 0.9106 - val_loss: 0.2862\n",
      "Epoch 211/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9215 - loss: 0.2541 - val_accuracy: 0.9088 - val_loss: 0.3010\n",
      "Epoch 212/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9245 - loss: 0.2324 - val_accuracy: 0.9106 - val_loss: 0.2872\n",
      "Epoch 213/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9127 - loss: 0.2652 - val_accuracy: 0.9052 - val_loss: 0.3012\n",
      "Epoch 214/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9131 - loss: 0.2758 - val_accuracy: 0.9123 - val_loss: 0.2886\n",
      "Epoch 215/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9029 - loss: 0.3063 - val_accuracy: 0.9123 - val_loss: 0.2899\n",
      "Epoch 216/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9229 - loss: 0.2548 - val_accuracy: 0.9106 - val_loss: 0.2918\n",
      "Epoch 217/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9164 - loss: 0.2646 - val_accuracy: 0.9088 - val_loss: 0.2825\n",
      "Epoch 218/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9185 - loss: 0.2597 - val_accuracy: 0.9052 - val_loss: 0.3050\n",
      "Epoch 219/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9131 - loss: 0.2789 - val_accuracy: 0.9070 - val_loss: 0.2921\n",
      "Epoch 220/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9274 - loss: 0.2395 - val_accuracy: 0.9106 - val_loss: 0.2860\n",
      "Epoch 221/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9183 - loss: 0.2565 - val_accuracy: 0.9141 - val_loss: 0.2815\n",
      "Epoch 222/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9160 - loss: 0.2647 - val_accuracy: 0.9106 - val_loss: 0.2930\n",
      "Epoch 223/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9179 - loss: 0.2726 - val_accuracy: 0.9070 - val_loss: 0.2968\n",
      "Epoch 224/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9187 - loss: 0.2664 - val_accuracy: 0.9052 - val_loss: 0.3088\n",
      "Epoch 225/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9162 - loss: 0.2687 - val_accuracy: 0.9088 - val_loss: 0.2916\n",
      "Epoch 226/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9178 - loss: 0.2563 - val_accuracy: 0.9106 - val_loss: 0.2847\n",
      "Epoch 227/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9297 - loss: 0.2408 - val_accuracy: 0.9088 - val_loss: 0.2985\n",
      "Epoch 228/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9108 - loss: 0.2832 - val_accuracy: 0.9052 - val_loss: 0.3065\n",
      "Epoch 229/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9089 - loss: 0.2861 - val_accuracy: 0.9123 - val_loss: 0.2845\n",
      "Epoch 230/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9244 - loss: 0.2442 - val_accuracy: 0.9106 - val_loss: 0.2938\n",
      "Epoch 231/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9165 - loss: 0.2543 - val_accuracy: 0.9141 - val_loss: 0.2873\n",
      "Epoch 232/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9108 - loss: 0.2811 - val_accuracy: 0.9070 - val_loss: 0.2947\n",
      "Epoch 233/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9175 - loss: 0.2769 - val_accuracy: 0.9106 - val_loss: 0.2837\n",
      "Epoch 234/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9237 - loss: 0.2467 - val_accuracy: 0.9106 - val_loss: 0.2885\n",
      "Epoch 235/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9116 - loss: 0.2674 - val_accuracy: 0.9052 - val_loss: 0.2971\n",
      "Epoch 236/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9217 - loss: 0.2415 - val_accuracy: 0.9034 - val_loss: 0.2984\n",
      "Epoch 237/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9112 - loss: 0.2728 - val_accuracy: 0.9106 - val_loss: 0.2878\n",
      "Epoch 238/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9193 - loss: 0.2593 - val_accuracy: 0.9123 - val_loss: 0.2923\n",
      "Epoch 239/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9243 - loss: 0.2460 - val_accuracy: 0.9088 - val_loss: 0.2930\n",
      "Epoch 240/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9202 - loss: 0.2524 - val_accuracy: 0.9123 - val_loss: 0.2811\n",
      "Epoch 241/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9275 - loss: 0.2345 - val_accuracy: 0.9141 - val_loss: 0.2821\n",
      "Epoch 242/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9264 - loss: 0.2398 - val_accuracy: 0.9106 - val_loss: 0.2821\n",
      "Epoch 243/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9183 - loss: 0.2642 - val_accuracy: 0.9070 - val_loss: 0.2897\n",
      "Epoch 244/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9217 - loss: 0.2555 - val_accuracy: 0.9123 - val_loss: 0.2871\n",
      "Epoch 245/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9158 - loss: 0.2649 - val_accuracy: 0.9123 - val_loss: 0.2942\n",
      "Epoch 246/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9137 - loss: 0.2867 - val_accuracy: 0.9141 - val_loss: 0.2805\n",
      "Epoch 247/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9210 - loss: 0.2438 - val_accuracy: 0.9123 - val_loss: 0.2874\n",
      "Epoch 248/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9308 - loss: 0.2267 - val_accuracy: 0.9070 - val_loss: 0.2936\n",
      "Epoch 249/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9199 - loss: 0.2542 - val_accuracy: 0.9123 - val_loss: 0.2869\n",
      "Epoch 250/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9249 - loss: 0.2473 - val_accuracy: 0.9141 - val_loss: 0.2859\n",
      "Epoch 251/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9325 - loss: 0.2076 - val_accuracy: 0.9123 - val_loss: 0.2864\n",
      "Epoch 252/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9247 - loss: 0.2377 - val_accuracy: 0.9106 - val_loss: 0.2895\n",
      "Epoch 253/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9200 - loss: 0.2602 - val_accuracy: 0.9106 - val_loss: 0.2917\n",
      "Epoch 254/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9223 - loss: 0.2517 - val_accuracy: 0.9141 - val_loss: 0.2842\n",
      "Epoch 255/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9165 - loss: 0.2597 - val_accuracy: 0.9123 - val_loss: 0.2896\n",
      "Epoch 256/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9227 - loss: 0.2470 - val_accuracy: 0.9123 - val_loss: 0.2882\n",
      "Epoch 257/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9168 - loss: 0.2622 - val_accuracy: 0.9159 - val_loss: 0.2864\n",
      "Epoch 258/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9199 - loss: 0.2704 - val_accuracy: 0.9088 - val_loss: 0.2895\n",
      "Epoch 259/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9170 - loss: 0.2645 - val_accuracy: 0.9016 - val_loss: 0.3022\n",
      "Epoch 260/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9121 - loss: 0.2759 - val_accuracy: 0.9141 - val_loss: 0.2853\n",
      "Epoch 261/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9293 - loss: 0.2382 - val_accuracy: 0.9106 - val_loss: 0.2868\n",
      "Epoch 262/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9242 - loss: 0.2459 - val_accuracy: 0.9141 - val_loss: 0.2836\n",
      "Epoch 263/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9211 - loss: 0.2443 - val_accuracy: 0.9123 - val_loss: 0.2862\n",
      "Epoch 264/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9231 - loss: 0.2509 - val_accuracy: 0.9088 - val_loss: 0.2866\n",
      "Epoch 265/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9251 - loss: 0.2358 - val_accuracy: 0.9106 - val_loss: 0.2903\n",
      "Epoch 266/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9162 - loss: 0.2609 - val_accuracy: 0.9141 - val_loss: 0.2839\n",
      "Epoch 267/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9216 - loss: 0.2654 - val_accuracy: 0.9141 - val_loss: 0.2862\n",
      "Epoch 268/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9265 - loss: 0.2403 - val_accuracy: 0.9106 - val_loss: 0.2954\n",
      "Epoch 269/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9215 - loss: 0.2401 - val_accuracy: 0.9106 - val_loss: 0.2874\n",
      "Epoch 270/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9218 - loss: 0.2564 - val_accuracy: 0.9106 - val_loss: 0.3043\n",
      "Epoch 271/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9181 - loss: 0.2535 - val_accuracy: 0.9141 - val_loss: 0.2886\n",
      "Epoch 272/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9215 - loss: 0.2474 - val_accuracy: 0.9106 - val_loss: 0.2897\n",
      "Epoch 273/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9248 - loss: 0.2360 - val_accuracy: 0.9088 - val_loss: 0.2994\n",
      "Epoch 274/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9192 - loss: 0.2547 - val_accuracy: 0.9088 - val_loss: 0.2980\n",
      "Epoch 275/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9229 - loss: 0.2376 - val_accuracy: 0.9070 - val_loss: 0.2977\n",
      "Epoch 276/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9257 - loss: 0.2374 - val_accuracy: 0.9034 - val_loss: 0.3114\n",
      "Epoch 277/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9212 - loss: 0.2658 - val_accuracy: 0.9106 - val_loss: 0.2928\n",
      "Epoch 278/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9265 - loss: 0.2411 - val_accuracy: 0.9123 - val_loss: 0.2888\n",
      "Epoch 279/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9307 - loss: 0.2144 - val_accuracy: 0.9088 - val_loss: 0.2948\n",
      "Epoch 280/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9159 - loss: 0.2651 - val_accuracy: 0.9106 - val_loss: 0.2921\n",
      "Epoch 281/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9268 - loss: 0.2464 - val_accuracy: 0.9052 - val_loss: 0.2911\n",
      "Epoch 282/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9181 - loss: 0.2742 - val_accuracy: 0.8998 - val_loss: 0.3056\n",
      "Epoch 283/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9209 - loss: 0.2662 - val_accuracy: 0.9088 - val_loss: 0.2882\n",
      "Epoch 284/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9240 - loss: 0.2430 - val_accuracy: 0.8980 - val_loss: 0.3183\n",
      "Epoch 285/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9185 - loss: 0.2690 - val_accuracy: 0.9106 - val_loss: 0.3019\n",
      "Epoch 286/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9179 - loss: 0.2639 - val_accuracy: 0.9034 - val_loss: 0.3047\n",
      "Epoch 287/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9117 - loss: 0.2647 - val_accuracy: 0.9123 - val_loss: 0.2813\n",
      "Epoch 288/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9222 - loss: 0.2449 - val_accuracy: 0.9123 - val_loss: 0.3002\n",
      "Epoch 289/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9203 - loss: 0.2559 - val_accuracy: 0.9106 - val_loss: 0.2885\n",
      "Epoch 290/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9316 - loss: 0.2192 - val_accuracy: 0.9123 - val_loss: 0.2859\n",
      "Epoch 291/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9138 - loss: 0.2767 - val_accuracy: 0.9088 - val_loss: 0.2939\n",
      "Epoch 292/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9198 - loss: 0.2526 - val_accuracy: 0.9123 - val_loss: 0.2875\n",
      "Epoch 293/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9199 - loss: 0.2506 - val_accuracy: 0.9159 - val_loss: 0.2896\n",
      "Epoch 294/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9172 - loss: 0.2541 - val_accuracy: 0.9141 - val_loss: 0.2891\n",
      "Epoch 295/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9173 - loss: 0.2547 - val_accuracy: 0.9123 - val_loss: 0.2920\n",
      "Epoch 296/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9204 - loss: 0.2662 - val_accuracy: 0.9070 - val_loss: 0.3082\n",
      "Epoch 297/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9270 - loss: 0.2221 - val_accuracy: 0.8945 - val_loss: 0.3483\n",
      "Epoch 298/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9159 - loss: 0.2636 - val_accuracy: 0.9016 - val_loss: 0.3203\n",
      "Epoch 299/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9213 - loss: 0.2485 - val_accuracy: 0.9106 - val_loss: 0.3023\n",
      "Epoch 300/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9242 - loss: 0.2442 - val_accuracy: 0.9123 - val_loss: 0.2912\n",
      "Epoch 301/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9206 - loss: 0.2523 - val_accuracy: 0.9106 - val_loss: 0.2886\n",
      "Epoch 302/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9130 - loss: 0.2872 - val_accuracy: 0.9106 - val_loss: 0.2943\n",
      "Epoch 303/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9275 - loss: 0.2272 - val_accuracy: 0.9141 - val_loss: 0.2900\n",
      "Epoch 304/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9213 - loss: 0.2659 - val_accuracy: 0.9141 - val_loss: 0.2897\n",
      "Epoch 305/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9244 - loss: 0.2319 - val_accuracy: 0.9141 - val_loss: 0.2885\n",
      "Epoch 306/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9246 - loss: 0.2446 - val_accuracy: 0.9141 - val_loss: 0.2946\n",
      "Epoch 307/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9201 - loss: 0.2622 - val_accuracy: 0.9141 - val_loss: 0.2925\n",
      "Epoch 308/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9200 - loss: 0.2637 - val_accuracy: 0.9106 - val_loss: 0.2946\n",
      "Epoch 309/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9253 - loss: 0.2526 - val_accuracy: 0.9159 - val_loss: 0.2894\n",
      "Epoch 310/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9261 - loss: 0.2282 - val_accuracy: 0.9070 - val_loss: 0.3065\n",
      "Epoch 311/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9270 - loss: 0.2339 - val_accuracy: 0.9141 - val_loss: 0.2867\n",
      "Epoch 312/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9306 - loss: 0.2250 - val_accuracy: 0.9141 - val_loss: 0.2904\n",
      "Epoch 313/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9214 - loss: 0.2575 - val_accuracy: 0.9123 - val_loss: 0.3005\n",
      "Epoch 314/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9151 - loss: 0.2728 - val_accuracy: 0.9088 - val_loss: 0.3026\n",
      "Epoch 315/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9179 - loss: 0.2590 - val_accuracy: 0.9123 - val_loss: 0.2894\n",
      "Epoch 316/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9229 - loss: 0.2582 - val_accuracy: 0.9141 - val_loss: 0.2973\n",
      "Epoch 317/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9252 - loss: 0.2352 - val_accuracy: 0.9123 - val_loss: 0.2949\n",
      "Epoch 318/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9144 - loss: 0.2606 - val_accuracy: 0.9123 - val_loss: 0.2893\n",
      "Epoch 319/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9196 - loss: 0.2555 - val_accuracy: 0.9141 - val_loss: 0.2873\n",
      "Epoch 320/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9282 - loss: 0.2405 - val_accuracy: 0.9106 - val_loss: 0.3032\n",
      "Epoch 321/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9269 - loss: 0.2339 - val_accuracy: 0.9106 - val_loss: 0.2965\n",
      "Epoch 322/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9242 - loss: 0.2431 - val_accuracy: 0.9123 - val_loss: 0.2830\n",
      "Epoch 323/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9217 - loss: 0.2488 - val_accuracy: 0.9123 - val_loss: 0.2849\n",
      "Epoch 324/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9179 - loss: 0.2687 - val_accuracy: 0.9159 - val_loss: 0.2839\n",
      "Epoch 325/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9141 - loss: 0.2734 - val_accuracy: 0.9106 - val_loss: 0.2941\n",
      "Epoch 326/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9216 - loss: 0.2542 - val_accuracy: 0.9159 - val_loss: 0.2805\n",
      "Epoch 327/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9255 - loss: 0.2411 - val_accuracy: 0.9159 - val_loss: 0.2925\n",
      "Epoch 328/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9183 - loss: 0.2629 - val_accuracy: 0.9088 - val_loss: 0.3032\n",
      "Epoch 329/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9291 - loss: 0.2274 - val_accuracy: 0.9123 - val_loss: 0.2914\n",
      "Epoch 330/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9287 - loss: 0.2272 - val_accuracy: 0.9123 - val_loss: 0.2857\n",
      "Epoch 331/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9247 - loss: 0.2453 - val_accuracy: 0.9123 - val_loss: 0.2963\n",
      "Epoch 332/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9210 - loss: 0.2523 - val_accuracy: 0.9016 - val_loss: 0.3183\n",
      "Epoch 333/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9293 - loss: 0.2234 - val_accuracy: 0.9141 - val_loss: 0.2958\n",
      "Epoch 334/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9258 - loss: 0.2370 - val_accuracy: 0.9141 - val_loss: 0.2871\n",
      "Epoch 335/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9298 - loss: 0.2312 - val_accuracy: 0.9088 - val_loss: 0.3013\n",
      "Epoch 336/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9166 - loss: 0.2670 - val_accuracy: 0.9141 - val_loss: 0.2919\n",
      "Epoch 337/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9212 - loss: 0.2485 - val_accuracy: 0.9106 - val_loss: 0.2913\n",
      "Epoch 338/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9230 - loss: 0.2645 - val_accuracy: 0.9141 - val_loss: 0.2837\n",
      "Epoch 339/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9250 - loss: 0.2407 - val_accuracy: 0.9141 - val_loss: 0.2958\n",
      "Epoch 340/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9226 - loss: 0.2411 - val_accuracy: 0.9052 - val_loss: 0.2993\n",
      "Epoch 341/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9263 - loss: 0.2164 - val_accuracy: 0.9123 - val_loss: 0.2950\n",
      "Epoch 342/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9250 - loss: 0.2352 - val_accuracy: 0.9141 - val_loss: 0.2867\n",
      "Epoch 343/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9222 - loss: 0.2420 - val_accuracy: 0.9088 - val_loss: 0.2991\n",
      "Epoch 344/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9162 - loss: 0.2613 - val_accuracy: 0.9070 - val_loss: 0.3038\n",
      "Epoch 345/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9256 - loss: 0.2379 - val_accuracy: 0.9123 - val_loss: 0.2888\n",
      "Epoch 346/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9247 - loss: 0.2527 - val_accuracy: 0.9141 - val_loss: 0.2883\n",
      "Epoch 347/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9142 - loss: 0.2714 - val_accuracy: 0.9141 - val_loss: 0.2840\n",
      "Epoch 348/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9262 - loss: 0.2393 - val_accuracy: 0.9106 - val_loss: 0.2980\n",
      "Epoch 349/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9179 - loss: 0.2551 - val_accuracy: 0.9106 - val_loss: 0.2931\n",
      "Epoch 350/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9181 - loss: 0.2515 - val_accuracy: 0.9106 - val_loss: 0.3039\n",
      "Epoch 351/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9169 - loss: 0.2500 - val_accuracy: 0.9123 - val_loss: 0.3068\n",
      "Epoch 352/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9148 - loss: 0.2669 - val_accuracy: 0.9106 - val_loss: 0.2961\n",
      "Epoch 353/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9228 - loss: 0.2512 - val_accuracy: 0.9159 - val_loss: 0.2904\n",
      "Epoch 354/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9334 - loss: 0.2236 - val_accuracy: 0.9123 - val_loss: 0.2899\n",
      "Epoch 355/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9274 - loss: 0.2419 - val_accuracy: 0.9123 - val_loss: 0.2955\n",
      "Epoch 356/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9211 - loss: 0.2553 - val_accuracy: 0.9123 - val_loss: 0.2996\n",
      "Epoch 357/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9279 - loss: 0.2363 - val_accuracy: 0.9106 - val_loss: 0.2937\n",
      "Epoch 358/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9285 - loss: 0.2336 - val_accuracy: 0.9123 - val_loss: 0.2926\n",
      "Epoch 359/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9210 - loss: 0.2457 - val_accuracy: 0.9123 - val_loss: 0.2918\n",
      "Epoch 360/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9226 - loss: 0.2541 - val_accuracy: 0.9141 - val_loss: 0.2894\n",
      "Epoch 361/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9304 - loss: 0.2221 - val_accuracy: 0.9123 - val_loss: 0.2940\n",
      "Epoch 362/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9233 - loss: 0.2480 - val_accuracy: 0.9141 - val_loss: 0.2985\n",
      "Epoch 363/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9217 - loss: 0.2457 - val_accuracy: 0.9141 - val_loss: 0.2934\n",
      "Epoch 364/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9202 - loss: 0.2544 - val_accuracy: 0.9070 - val_loss: 0.3286\n",
      "Epoch 365/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9113 - loss: 0.2868 - val_accuracy: 0.9106 - val_loss: 0.3009\n",
      "Epoch 366/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9198 - loss: 0.2522 - val_accuracy: 0.9141 - val_loss: 0.2865\n",
      "Epoch 367/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9252 - loss: 0.2442 - val_accuracy: 0.9123 - val_loss: 0.2834\n",
      "Epoch 368/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9340 - loss: 0.2226 - val_accuracy: 0.9141 - val_loss: 0.2867\n",
      "Epoch 369/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9211 - loss: 0.2503 - val_accuracy: 0.9052 - val_loss: 0.3077\n",
      "Epoch 370/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9194 - loss: 0.2547 - val_accuracy: 0.9123 - val_loss: 0.2971\n",
      "Epoch 371/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9318 - loss: 0.2299 - val_accuracy: 0.9106 - val_loss: 0.2955\n",
      "Epoch 372/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9112 - loss: 0.2665 - val_accuracy: 0.9123 - val_loss: 0.2924\n",
      "Epoch 373/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9093 - loss: 0.2789 - val_accuracy: 0.9141 - val_loss: 0.2895\n",
      "Epoch 374/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9148 - loss: 0.2583 - val_accuracy: 0.9106 - val_loss: 0.3008\n",
      "Epoch 375/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9304 - loss: 0.2261 - val_accuracy: 0.9123 - val_loss: 0.2954\n",
      "Epoch 376/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9281 - loss: 0.2374 - val_accuracy: 0.9141 - val_loss: 0.2924\n",
      "Epoch 377/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9136 - loss: 0.2704 - val_accuracy: 0.9070 - val_loss: 0.3071\n",
      "Epoch 378/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9124 - loss: 0.2827 - val_accuracy: 0.9141 - val_loss: 0.2926\n",
      "Epoch 379/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9251 - loss: 0.2319 - val_accuracy: 0.9141 - val_loss: 0.2888\n",
      "Epoch 380/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9227 - loss: 0.2449 - val_accuracy: 0.9070 - val_loss: 0.3047\n",
      "Epoch 381/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9310 - loss: 0.2180 - val_accuracy: 0.9159 - val_loss: 0.2874\n",
      "Epoch 382/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9132 - loss: 0.2770 - val_accuracy: 0.9123 - val_loss: 0.3033\n",
      "Epoch 383/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9173 - loss: 0.2736 - val_accuracy: 0.9123 - val_loss: 0.2972\n",
      "Epoch 384/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9302 - loss: 0.2275 - val_accuracy: 0.9141 - val_loss: 0.2885\n",
      "Epoch 385/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9223 - loss: 0.2590 - val_accuracy: 0.9123 - val_loss: 0.2852\n",
      "Epoch 386/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9207 - loss: 0.2510 - val_accuracy: 0.9106 - val_loss: 0.2939\n",
      "Epoch 387/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9244 - loss: 0.2354 - val_accuracy: 0.9141 - val_loss: 0.2938\n",
      "Epoch 388/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9124 - loss: 0.2779 - val_accuracy: 0.9141 - val_loss: 0.3043\n",
      "Epoch 389/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9308 - loss: 0.2252 - val_accuracy: 0.9123 - val_loss: 0.2948\n",
      "Epoch 390/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9315 - loss: 0.2147 - val_accuracy: 0.9088 - val_loss: 0.3098\n",
      "Epoch 391/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9189 - loss: 0.2658 - val_accuracy: 0.9123 - val_loss: 0.2989\n",
      "Epoch 392/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9174 - loss: 0.2599 - val_accuracy: 0.9016 - val_loss: 0.3147\n",
      "Epoch 393/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9103 - loss: 0.2634 - val_accuracy: 0.9088 - val_loss: 0.2939\n",
      "Epoch 394/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9246 - loss: 0.2467 - val_accuracy: 0.9141 - val_loss: 0.2880\n",
      "Epoch 395/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9308 - loss: 0.2305 - val_accuracy: 0.9141 - val_loss: 0.2901\n",
      "Epoch 396/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9220 - loss: 0.2549 - val_accuracy: 0.9123 - val_loss: 0.2933\n",
      "Epoch 397/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9208 - loss: 0.2673 - val_accuracy: 0.9070 - val_loss: 0.3090\n",
      "Epoch 398/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9165 - loss: 0.2722 - val_accuracy: 0.9123 - val_loss: 0.2868\n",
      "Epoch 399/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9212 - loss: 0.2568 - val_accuracy: 0.9123 - val_loss: 0.2906\n",
      "Epoch 400/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9228 - loss: 0.2517 - val_accuracy: 0.9141 - val_loss: 0.2894\n",
      "Epoch 401/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9224 - loss: 0.2394 - val_accuracy: 0.9141 - val_loss: 0.2956\n",
      "Epoch 402/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9204 - loss: 0.2403 - val_accuracy: 0.9088 - val_loss: 0.3079\n",
      "Epoch 403/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9312 - loss: 0.2136 - val_accuracy: 0.9106 - val_loss: 0.3100\n",
      "Epoch 404/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9319 - loss: 0.2078 - val_accuracy: 0.9016 - val_loss: 0.3215\n",
      "Epoch 405/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9123 - loss: 0.2883 - val_accuracy: 0.9159 - val_loss: 0.2895\n",
      "Epoch 406/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9110 - loss: 0.2853 - val_accuracy: 0.9141 - val_loss: 0.2954\n",
      "Epoch 407/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9109 - loss: 0.2806 - val_accuracy: 0.9052 - val_loss: 0.3043\n",
      "Epoch 408/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9263 - loss: 0.2342 - val_accuracy: 0.9141 - val_loss: 0.2894\n",
      "Epoch 409/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9197 - loss: 0.2458 - val_accuracy: 0.9106 - val_loss: 0.2968\n",
      "Epoch 410/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9232 - loss: 0.2461 - val_accuracy: 0.9123 - val_loss: 0.2961\n",
      "Epoch 411/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9296 - loss: 0.2344 - val_accuracy: 0.9123 - val_loss: 0.3002\n",
      "Epoch 412/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9281 - loss: 0.2327 - val_accuracy: 0.9141 - val_loss: 0.2893\n",
      "Epoch 413/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9271 - loss: 0.2315 - val_accuracy: 0.9106 - val_loss: 0.2859\n",
      "Epoch 414/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9298 - loss: 0.2257 - val_accuracy: 0.9141 - val_loss: 0.2868\n",
      "Epoch 415/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9226 - loss: 0.2433 - val_accuracy: 0.9141 - val_loss: 0.2979\n",
      "Epoch 416/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9158 - loss: 0.2616 - val_accuracy: 0.9052 - val_loss: 0.3071\n",
      "Epoch 417/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9226 - loss: 0.2502 - val_accuracy: 0.9141 - val_loss: 0.2900\n",
      "Epoch 418/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9241 - loss: 0.2413 - val_accuracy: 0.9141 - val_loss: 0.2884\n",
      "Epoch 419/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9299 - loss: 0.2284 - val_accuracy: 0.9123 - val_loss: 0.2927\n",
      "Epoch 420/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9199 - loss: 0.2523 - val_accuracy: 0.9088 - val_loss: 0.3036\n",
      "Epoch 421/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9221 - loss: 0.2418 - val_accuracy: 0.9159 - val_loss: 0.2921\n",
      "Epoch 422/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9224 - loss: 0.2393 - val_accuracy: 0.9123 - val_loss: 0.3029\n",
      "Epoch 423/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9285 - loss: 0.2339 - val_accuracy: 0.9106 - val_loss: 0.3038\n",
      "Epoch 424/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9188 - loss: 0.2514 - val_accuracy: 0.9141 - val_loss: 0.2916\n",
      "Epoch 425/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9282 - loss: 0.2330 - val_accuracy: 0.9141 - val_loss: 0.2930\n",
      "Epoch 426/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9245 - loss: 0.2527 - val_accuracy: 0.9141 - val_loss: 0.2935\n",
      "Epoch 427/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.2199 - val_accuracy: 0.9141 - val_loss: 0.2861\n",
      "Epoch 428/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9269 - loss: 0.2347 - val_accuracy: 0.9141 - val_loss: 0.2854\n",
      "Epoch 429/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9220 - loss: 0.2559 - val_accuracy: 0.9123 - val_loss: 0.2983\n",
      "Epoch 430/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9372 - loss: 0.2022 - val_accuracy: 0.9141 - val_loss: 0.2956\n",
      "Epoch 431/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9318 - loss: 0.2200 - val_accuracy: 0.9141 - val_loss: 0.3027\n",
      "Epoch 432/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9190 - loss: 0.2494 - val_accuracy: 0.9159 - val_loss: 0.2873\n",
      "Epoch 433/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9337 - loss: 0.2192 - val_accuracy: 0.9141 - val_loss: 0.2907\n",
      "Epoch 434/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9227 - loss: 0.2475 - val_accuracy: 0.9141 - val_loss: 0.2948\n",
      "Epoch 435/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9285 - loss: 0.2269 - val_accuracy: 0.9123 - val_loss: 0.2942\n",
      "Epoch 436/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9250 - loss: 0.2455 - val_accuracy: 0.9123 - val_loss: 0.2960\n",
      "Epoch 437/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9336 - loss: 0.2123 - val_accuracy: 0.9141 - val_loss: 0.2998\n",
      "Epoch 438/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9207 - loss: 0.2478 - val_accuracy: 0.9141 - val_loss: 0.2905\n",
      "Epoch 439/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9229 - loss: 0.2443 - val_accuracy: 0.9123 - val_loss: 0.2958\n",
      "Epoch 440/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9271 - loss: 0.2331 - val_accuracy: 0.9141 - val_loss: 0.2985\n",
      "Epoch 441/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9236 - loss: 0.2438 - val_accuracy: 0.9123 - val_loss: 0.2996\n",
      "Epoch 442/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9320 - loss: 0.2174 - val_accuracy: 0.9141 - val_loss: 0.2954\n",
      "Epoch 443/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9285 - loss: 0.2279 - val_accuracy: 0.9141 - val_loss: 0.3034\n",
      "Epoch 444/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9227 - loss: 0.2565 - val_accuracy: 0.9123 - val_loss: 0.2998\n",
      "Epoch 445/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9274 - loss: 0.2325 - val_accuracy: 0.9141 - val_loss: 0.2985\n",
      "Epoch 446/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9190 - loss: 0.2487 - val_accuracy: 0.9141 - val_loss: 0.3026\n",
      "Epoch 447/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9264 - loss: 0.2348 - val_accuracy: 0.9123 - val_loss: 0.2939\n",
      "Epoch 448/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9219 - loss: 0.2307 - val_accuracy: 0.9123 - val_loss: 0.2986\n",
      "Epoch 449/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9129 - loss: 0.2639 - val_accuracy: 0.9123 - val_loss: 0.3006\n",
      "Epoch 450/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9178 - loss: 0.2602 - val_accuracy: 0.9034 - val_loss: 0.3467\n",
      "Epoch 451/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9220 - loss: 0.2501 - val_accuracy: 0.8909 - val_loss: 0.3596\n",
      "Epoch 452/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9163 - loss: 0.2755 - val_accuracy: 0.9106 - val_loss: 0.3084\n",
      "Epoch 453/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9244 - loss: 0.2307 - val_accuracy: 0.9088 - val_loss: 0.3288\n",
      "Epoch 454/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9263 - loss: 0.2334 - val_accuracy: 0.9141 - val_loss: 0.2972\n",
      "Epoch 455/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9130 - loss: 0.2703 - val_accuracy: 0.9123 - val_loss: 0.3054\n",
      "Epoch 456/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9259 - loss: 0.2481 - val_accuracy: 0.9123 - val_loss: 0.3051\n",
      "Epoch 457/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9210 - loss: 0.2641 - val_accuracy: 0.9141 - val_loss: 0.2972\n",
      "Epoch 458/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9209 - loss: 0.2510 - val_accuracy: 0.9106 - val_loss: 0.3091\n",
      "Epoch 459/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9245 - loss: 0.2336 - val_accuracy: 0.9070 - val_loss: 0.3305\n",
      "Epoch 460/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9124 - loss: 0.2711 - val_accuracy: 0.9106 - val_loss: 0.3122\n",
      "Epoch 461/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9242 - loss: 0.2348 - val_accuracy: 0.9034 - val_loss: 0.3435\n",
      "Epoch 462/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9128 - loss: 0.2810 - val_accuracy: 0.9106 - val_loss: 0.3107\n",
      "Epoch 463/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9269 - loss: 0.2242 - val_accuracy: 0.9123 - val_loss: 0.3052\n",
      "Epoch 464/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9245 - loss: 0.2447 - val_accuracy: 0.9141 - val_loss: 0.2983\n",
      "Epoch 465/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9171 - loss: 0.2736 - val_accuracy: 0.9141 - val_loss: 0.3027\n",
      "Epoch 466/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9282 - loss: 0.2367 - val_accuracy: 0.9141 - val_loss: 0.3009\n",
      "Epoch 467/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9307 - loss: 0.2235 - val_accuracy: 0.9141 - val_loss: 0.2930\n",
      "Epoch 468/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9182 - loss: 0.2488 - val_accuracy: 0.9141 - val_loss: 0.2987\n",
      "Epoch 469/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9291 - loss: 0.2272 - val_accuracy: 0.9141 - val_loss: 0.2997\n",
      "Epoch 470/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9231 - loss: 0.2333 - val_accuracy: 0.9141 - val_loss: 0.3014\n",
      "Epoch 471/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9339 - loss: 0.2230 - val_accuracy: 0.9106 - val_loss: 0.3036\n",
      "Epoch 472/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9257 - loss: 0.2386 - val_accuracy: 0.9141 - val_loss: 0.2968\n",
      "Epoch 473/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9165 - loss: 0.2458 - val_accuracy: 0.9088 - val_loss: 0.3120\n",
      "Epoch 474/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9180 - loss: 0.2648 - val_accuracy: 0.9016 - val_loss: 0.3199\n",
      "Epoch 475/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9226 - loss: 0.2355 - val_accuracy: 0.9123 - val_loss: 0.3066\n",
      "Epoch 476/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9179 - loss: 0.2705 - val_accuracy: 0.9123 - val_loss: 0.3076\n",
      "Epoch 477/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9219 - loss: 0.2391 - val_accuracy: 0.9141 - val_loss: 0.3052\n",
      "Epoch 478/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9208 - loss: 0.2519 - val_accuracy: 0.9141 - val_loss: 0.2979\n",
      "Epoch 479/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9156 - loss: 0.2600 - val_accuracy: 0.9141 - val_loss: 0.3031\n",
      "Epoch 480/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9266 - loss: 0.2369 - val_accuracy: 0.9141 - val_loss: 0.3018\n",
      "Epoch 481/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9291 - loss: 0.2348 - val_accuracy: 0.9141 - val_loss: 0.3049\n",
      "Epoch 482/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9190 - loss: 0.2566 - val_accuracy: 0.9141 - val_loss: 0.2988\n",
      "Epoch 483/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9218 - loss: 0.2557 - val_accuracy: 0.9106 - val_loss: 0.3115\n",
      "Epoch 484/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 0.2303 - val_accuracy: 0.9141 - val_loss: 0.3008\n",
      "Epoch 485/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9195 - loss: 0.2596 - val_accuracy: 0.9141 - val_loss: 0.2957\n",
      "Epoch 486/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9281 - loss: 0.2195 - val_accuracy: 0.9141 - val_loss: 0.2944\n",
      "Epoch 487/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9207 - loss: 0.2482 - val_accuracy: 0.9123 - val_loss: 0.3119\n",
      "Epoch 488/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9268 - loss: 0.2321 - val_accuracy: 0.9106 - val_loss: 0.3072\n",
      "Epoch 489/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9200 - loss: 0.2565 - val_accuracy: 0.9141 - val_loss: 0.2997\n",
      "Epoch 490/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9244 - loss: 0.2391 - val_accuracy: 0.9141 - val_loss: 0.3030\n",
      "Epoch 491/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9229 - loss: 0.2435 - val_accuracy: 0.9141 - val_loss: 0.2980\n",
      "Epoch 492/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9212 - loss: 0.2498 - val_accuracy: 0.9141 - val_loss: 0.3015\n",
      "Epoch 493/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9229 - loss: 0.2503 - val_accuracy: 0.9141 - val_loss: 0.2982\n",
      "Epoch 494/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9289 - loss: 0.2318 - val_accuracy: 0.9141 - val_loss: 0.2935\n",
      "Epoch 495/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9166 - loss: 0.2647 - val_accuracy: 0.9159 - val_loss: 0.3021\n",
      "Epoch 496/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9241 - loss: 0.2320 - val_accuracy: 0.9123 - val_loss: 0.3048\n",
      "Epoch 497/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9230 - loss: 0.2495 - val_accuracy: 0.9141 - val_loss: 0.3022\n",
      "Epoch 498/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9273 - loss: 0.2283 - val_accuracy: 0.9141 - val_loss: 0.3002\n",
      "Epoch 499/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9299 - loss: 0.2250 - val_accuracy: 0.9123 - val_loss: 0.3042\n",
      "Epoch 500/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9157 - loss: 0.2617 - val_accuracy: 0.9141 - val_loss: 0.3001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29ab01d6450>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = svm.SVC(decision_function_shape='ovo')\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# model = RandomForestClassifier(max_depth=9, random_state=0)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # keras.layers.Dropout(0.5),\n",
    "   #  keras.layers.Dense(30, activation='relu'),\n",
    "   #  keras.layers.Dropout(0.5),\n",
    "   #  keras.layers.Dense(15, activation='relu'),\n",
    "   # #  keras.layers.Dropout(0.5),\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(63,)),  # 21 landmarks * 3 coordinates\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(np.unique(y_encoded)), activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=63, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de63a9ef-640c-43ea-882b-f13332920c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[ 3.41040969e-01  6.64668560e-01 -1.64455912e-07  4.05093998e-01\n",
      "  6.28210425e-01 -1.36750080e-02  4.48419780e-01  5.68777502e-01\n",
      " -1.45512959e-02  4.75034207e-01  5.14351189e-01 -1.78712383e-02\n",
      "  4.94595438e-01  4.80084360e-01 -2.10941248e-02  4.02668744e-01\n",
      "  4.82772648e-01  5.94023895e-03  4.12792891e-01  4.01649147e-01\n",
      " -2.80971732e-03  4.16507930e-01  3.57204914e-01 -7.72492727e-03\n",
      "  4.20436680e-01  3.16816449e-01 -1.10468036e-02  3.67001742e-01\n",
      "  4.83677626e-01  2.39770254e-03  3.72743636e-01  4.25600082e-01\n",
      " -3.09506059e-02  3.76547009e-01  4.82813954e-01 -4.60818075e-02\n",
      "  3.78788412e-01  5.31814277e-01 -4.57099937e-02  3.32709819e-01\n",
      "  4.90523607e-01 -3.29517317e-03  3.33672047e-01  4.35255229e-01\n",
      " -3.64301465e-02  3.43398035e-01  4.92767632e-01 -4.01473530e-02\n",
      "  3.49583149e-01  5.36802649e-01 -3.15928459e-02  2.97491819e-01\n",
      "  5.01111329e-01 -9.94537771e-03  2.81915873e-01  4.37529832e-01\n",
      " -2.81374734e-02  2.77353704e-01  4.00262743e-01 -3.13893519e-02\n",
      "  2.74940878e-01  3.57106149e-01 -2.93808375e-02]\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./numbers_1_hand_signs/99_143/13.jpg\")\n",
    "\n",
    "imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
    "results = hands.process(imgRGB)\n",
    "\n",
    "if results.multi_hand_landmarks:\n",
    "    for handLms in results.multi_hand_landmarks:\n",
    "        a = []\n",
    "        for id, lm in enumerate(handLms.landmark):\n",
    "            temp =[]\n",
    "            temp.append(lm.x)\n",
    "            temp.append(lm.y)\n",
    "            temp.append(lm.z)\n",
    "            a.append(temp)\n",
    "        print(len(a))\n",
    "        Numpy_array = np.array(a)\n",
    "        flatten_array = Numpy_array.flatten()\n",
    "        print(flatten_array)\n",
    "        print(len(flatten_array))\n",
    "\n",
    "# Assuming flatten_array is your 1D array with 63 elements\n",
    "flatten_array = np.array(flatten_array).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd21c853-756f-48fc-b3f8-5f3d1f6329ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "[[3.3129253e-09 1.5591494e-29 2.0389379e-27 ... 9.8431073e-16\n",
      "  9.9999833e-01 2.6602991e-21]\n",
      " [1.6688349e-32 3.4234312e-31 5.7631812e-18 ... 8.4861834e-10\n",
      "  2.1805764e-32 2.3633400e-16]\n",
      " [3.9832353e-17 3.0159585e-27 2.5879804e-31 ... 2.9394638e-24\n",
      "  9.9999988e-01 1.4231340e-26]\n",
      " ...\n",
      " [0.0000000e+00 6.0029330e-23 7.0373291e-17 ... 6.0457620e-14\n",
      "  1.4133956e-35 3.6205348e-15]\n",
      " [1.1544602e-34 9.9998093e-01 6.3917875e-09 ... 8.7455493e-30\n",
      "  8.4441493e-35 6.8965917e-21]\n",
      " [2.0977168e-06 4.8931545e-29 1.2933889e-16 ... 2.0049454e-03\n",
      "  9.0501608e-12 2.4191129e-12]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m class_dict \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelete\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mj\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m class_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted class index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mclass_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "output = model.predict( X_test)\n",
    "print(output)# Assuming 'class_index' is the predicted index\n",
    "\n",
    "class_dict = ['a', 'b', 'c', 'd',\"Delete\", 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's',\"Space\", 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "\n",
    "class_index = np.argmax(output)\n",
    "\n",
    "print(f\"Predicted class index: {class_dict[class_index]}\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f7dff9f-28e5-47ff-a757-1f75568e6bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'Delete',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 'Space',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74d51862-1b98-42ad-82f8-0b39cb9d8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('model2_alpha_f.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89c46d8-bf9b-4908-9ec2-10450d52baab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m accuracy\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:227\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m    226\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[1;32m--> 227\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    109\u001b[0m             type_true, type_pred\n\u001b[0;32m    110\u001b[0m         )\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, output, normalize=True, sample_weight=None)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec6b95-e58f-47ab-af73-ee0856c4c290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
